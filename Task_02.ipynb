{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flosch9/deep_learning_home_exam/blob/main/Task_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount drive for loading data"
      ],
      "metadata": {
        "id": "Nt3-MycpxKDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-PLNuxH1zdm",
        "outputId": "aba8bf2d-b1bb-4ce4-ad6d-8982fa9bee6f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define and load model (model.py)\n",
        "\n",
        "```\n",
        "# Als Code formatiert\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dfS5ObhvvHNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "\n",
        "\n",
        "class FCN32(nn.Module):\n",
        "    def __init__(self, output_size = (128,128), num_classes = 2, small_vgg = False):\n",
        "        super(FCN32, self).__init__()\n",
        "\n",
        "        # first part is regualr vgg16 (without batch normalization)?\n",
        "        if small_vgg:\n",
        "          self.features = vgg16(weights = VGG16_Weights.IMAGENET1K_V1).features[0:28]\n",
        "        else:\n",
        "          self.features = vgg16(weights = VGG16_Weights.IMAGENET1K_V1).features\n",
        "\n",
        "\n",
        "        # only choose some parts of vgg16? [0:28]\n",
        "        # set ceil mode to true\n",
        "        #self.features[6].ceil_mode = True\n",
        "        #self.features[13].ceil_mode = True\n",
        "        #self.features[23].ceil_mode = True\n",
        "        #self.features[33].ceil_mode = True\n",
        "        #self.features[43].ceil_mode = True\n",
        "\n",
        "        # classifier is now replaced with another cnn (instead of a fc)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Conv2d(512, 4024, kernel_size=(3,3), stride=(1,1), padding=(1,1)), # 512 output from last cnn/maxpool layer #maybe only 1000 channels\n",
        "            # use filter size 1024 or 4096\n",
        "            nn.ReLU(True),\n",
        "            #with Relu? with Batchnorm? with maxpool?\n",
        "            # 7x7 filter\n",
        "            nn.Conv2d(4024, num_classes, kernel_size=1, stride=(1,1), padding=(1,1))\n",
        "            #nn.ReLU(True)\n",
        "\n",
        "            #nn.Softmax()\n",
        "            #softmax produces niceer output in the end\n",
        "\n",
        "            # makes difference in the output, and in the loss which (none) activation is used\n",
        "        )\n",
        "        self.upsample = nn.Sequential(\n",
        "            # what is with upsampling meant? this (just resizing) or the deconvolution before upsample and transposeconv2d the same???\n",
        "            # this one is not trainable but easier\n",
        "            nn.UpsamplingBilinear2d(size=(output_size)),\n",
        "            nn.Softmax()\n",
        "\n",
        "            #nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2, padding=0)#, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)\n",
        "            # then output needs to be adjusted and classes in one channel\n",
        "            # try to set ceiling of maxpool to true\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        #print(\"Output after classifier\")\n",
        "        #print(x.shape)\n",
        "        x = self.upsample(x)\n",
        "        #print(\"Output after upsampling\")\n",
        "        #print(x.shape)\n",
        "        return x\n",
        "\n",
        "#model = FCN32(output_size=(128,128))\n",
        "\n",
        "# print outputs of a model\n",
        "#print(vgg16_bn().features)\n",
        "#print(vgg16_bn().classifier)\n",
        "\n",
        "#print(vgg16_bn())\n",
        "#model = FCN32()\n",
        "\n",
        "# print(FCN32().features)\n",
        "# set ceil_modes to true\n",
        "#print(model.features[6].ceil_mode)\n",
        "\n"
      ],
      "metadata": {
        "id": "r-J0ghhDvoCf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount drive to load data from drive"
      ],
      "metadata": {
        "id": "Lya780NE5QvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fw7o-Z81KfC",
        "outputId": "440a6999-e0c0-471b-fe7f-189e06d2cac5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/drive/MyDrive/Deep_learning_home_exam\""
      ],
      "metadata": {
        "id": "edPie4At5WhN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eXqMHU6TvE_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define train and test functions (traintestfuncs.py)"
      ],
      "metadata": {
        "id": "bp7kvPYnv3Tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import PILToTensor, ToTensor, ToPILImage, Resize\n",
        "\n",
        "# not needed in notebook\n",
        "#from model import FCN32\n",
        "\n",
        "\n",
        "def smallerDataset(dataset, size):\n",
        "\n",
        "    smaller_dataset = []\n",
        "\n",
        "    for i in range(size):\n",
        "        smaller_dataset.append(dataset[i])\n",
        "\n",
        "    return(smaller_dataset)\n",
        "\n",
        "\n",
        "# since the dataloader can t handle the PIL Image class of the original dataset\n",
        "# for each batch the lables and images have to be stacked to a tensor manually\n",
        "# in this step also the PIL Images are transformed to a tensor\n",
        "# do not use ToTensor for target image since it destroys the class\n",
        "def customCollate(batch, resize):\n",
        "\n",
        "    images = []\n",
        "    labels_orig = []\n",
        "    labels_merched = []\n",
        "\n",
        "    for dataset in batch:\n",
        "        image = ToTensor()(dataset[0])\n",
        "        label = PILToTensor()(dataset[1]) # important else target fckd up with classes\n",
        "        label = label.view(resize) #to get rid of the (implizit) given channel\n",
        "\n",
        "        label = label.long() # also importantz for CE-Loss, excpects long\n",
        "        #print(torch.unique(label))\n",
        "        # merching classes background and border\n",
        "        label_merched = torch.where(label == 3, 1, label)\n",
        "        #print(torch.unique(label))\n",
        "        label_merched = torch.sub(label_merched, 1) # also important since 3 classes -> [0,3), but original it was [1,3]\n",
        "        #print(torch.unique(label_merched))\n",
        "        label_orig = torch.sub(label, 1)\n",
        "        #print(torch.unique(label_orig))\n",
        "\n",
        "        images.append(image)\n",
        "        labels_merched.append(label_merched)\n",
        "        labels_orig.append(label_orig)\n",
        "\n",
        "    return(torch.stack(images), torch.stack(labels_merched), torch.stack(labels_orig))\n",
        "\n",
        "\n",
        "def showLosses(training_loss, test_loss, path_to_save):\n",
        "  return()\n",
        "\n",
        "\n",
        "def testModel(model, lossFunction, test_dataload):\n",
        "\n",
        "  test_loss = 0\n",
        "\n",
        "  for i, dataset in enumerate(test_dataload):\n",
        "\n",
        "        # unpack images and labels of batch\n",
        "        images , labels, labels_orig = dataset\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        output = model(images)\n",
        "\n",
        "        # compute loss\n",
        "        loss = lossFunction(output, labels)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "\n",
        "  return(test_loss)\n",
        "\n",
        "\n",
        "def trainBatch(model, lossFunction, Optimizer,\n",
        "              train_dataload, test_dataload,\n",
        "              NUMBEREPOCHS, FOLDERPATH):\n",
        "\n",
        "  running_loss = 0\n",
        "  batch_number = 0\n",
        "\n",
        "  for i, dataset in enumerate(train_dataload):\n",
        "\n",
        "      # unpack images and labels of batch\n",
        "      images , labels, _ = dataset\n",
        "\n",
        "      # reset optimizer gradients\n",
        "      Optimizer.zero_grad()\n",
        "\n",
        "      # forward pass\n",
        "      outputs = model(images)\n",
        "\n",
        "      # compute loss\n",
        "      loss = lossFunction(outputs, labels)\n",
        "\n",
        "      loss.backward()\n",
        "      Optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      batch_number += 1\n",
        "\n",
        "\n",
        "\n",
        "  return(running_loss, batch_number)\n",
        "\n",
        "\n",
        "def trainModel(model, lossFunction, Optimizer,\n",
        "              train_dataload, test_dataload,\n",
        "              NUMBEREPOCHS, FOLDERPATH):\n",
        "\n",
        "  training_loss = np.zeros(NUMBEREPOCHS)\n",
        "  test_loss = np.zeros(NUMBEREPOCHS)\n",
        "\n",
        "  for epoch in range(NUMBEREPOCHS):\n",
        "\n",
        "    # train every batch\n",
        "    running_loss, batch_number = trainBatch(model, lossFunction,\n",
        "                                           Optimizer, train_dataload,\n",
        "                                           test_dataload, NUMBEREPOCHS,\n",
        "                                           FOLDERPATH)\n",
        "\n",
        "    # test in each epoch\n",
        "    test_loss[epoch] = testModel(model, lossFunction, test_dataload)\n",
        "\n",
        "    # print epoch statistics\n",
        "    training_loss[epoch] = running_loss / batch_number\n",
        "    print(\"\\nEpoch [{}/{}]\".format(epoch+1,NUMBEREPOCHS))\n",
        "    print(\"{} updates in this epoch.\".format(batch_number))\n",
        "    print(\"Trainingloss: {}\".format(training_loss[epoch]))\n",
        "    print(\"Testingloss: {}\".format(test_loss[epoch]))\n",
        "\n",
        "\n",
        "\n",
        "  return(training_loss, test_loss)\n",
        "\n",
        "\n",
        "def evaluateFCN():\n",
        "  return()\n",
        "\n",
        "\n",
        "def test_model(model, test_images, test_labels_merched, original_labels):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    output = model(test_images)\n",
        "\n",
        "    show_output(test_images[0], output[0])\n",
        "\n",
        "    return()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# short function for displaying initial image next to segmentation\n",
        "def display_data(data_point):\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize =(10,6))\n",
        "    ax[0].imshow(ToPILImage()(data_point[0][0]))\n",
        "    ax[1].imshow(ToPILImage()(data_point[1][0]))\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return()\n",
        "\n",
        "###############################################################################\n",
        "# testing model and displaying outputs\n",
        "###############################################################################\n",
        "\n",
        "def show_output(initial_image, model_output):\n",
        "\n",
        "    #print(\"Shape initial: {}\".format(initial_image.shape)) #(3, H,W)\n",
        "    #print(\"Shape segmentation: {}\".format(model_output.shape)) #(2,H,W)\n",
        "    #print(\"Unique values segmentation: {}\".format(torch.unique(model_output)))\n",
        "    #print(\"Output segmentation:\")\n",
        "    #print(model_output)\n",
        "\n",
        "    model_output = model_output[1,:,:]\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize =(10,6))\n",
        "    ax[0].imshow(ToPILImage()(initial_image))\n",
        "    ax[1].imshow(ToPILImage()(model_output), cmap = \"gray\")\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    return()\n",
        "\n",
        "\n",
        "def show_uncertainity_map():\n",
        "    return()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1ij5b-Qhv7P2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and evaluate model (main.py)"
      ],
      "metadata": {
        "id": "czdp_KzuvtfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import utils\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import PILToTensor, ToTensor, ToPILImage, Resize\n",
        "\n",
        "#from model import FCN32\n",
        "#import traintestfuncs\n",
        "\n",
        "#from test import show_output, test_model, show_uncertainity_map\n",
        "\n",
        "###############################################################################\n",
        "# general Parameters for training (make adjustments here)\n",
        "###############################################################################\n",
        "# Path for notebook\n",
        "ROOTPATH = \"/content/drive/MyDrive/Deep_learning_home_exam/data/problem2/\"\n",
        "\n",
        "# Path for local\n",
        "#ROOTPATH = \"home_exam\\data\\problem2\\\\\"\n",
        "\n",
        "# for saving model with trained parameters\n",
        "VERSION = \"02\"\n",
        "\n",
        "MODE = \"train\" # \"train\" or \"evaluate\"\n",
        "\n",
        "# parameters for training\n",
        "NUMBEREPOCHS = 10\n",
        "BATCHSIZE = 2\n",
        "LEARNINGRATE = 0.001\n",
        "\n",
        "# resize dataset to see faster runtrough\n",
        "SMALLDATASET = True\n",
        "smaller_train_dataset_size = 10\n",
        "smaller_test_dataset_size = 10\n",
        "\n",
        "\n",
        "# resizing images of dataset so that they all have the same size\n",
        "# (which they originaly dont have)\n",
        "RESIZE =(512,512)\n",
        "# 56 too small\n",
        "#  128 #TODO\n",
        "# 256 ok -> version 01\n",
        "# resize to smaller images (not really good)\n",
        "\n",
        "# bigger image better, together with drop of last two maxpool layers\n",
        "\n",
        "# resize to smaller image maybe\n",
        "# use kernelsize 7x7 in last step of convolution output\n",
        "# google collab train on\n",
        "\n",
        "PRETRAINED = True\n",
        "SMALLVGG = False\n",
        "\n",
        "model = FCN32(output_size=RESIZE, num_classes=2, small_vgg = SMALLVGG)\n",
        "\n",
        "lossFunction = nn.CrossEntropyLoss() #nn.MSELoss()\n",
        "\n",
        "Optimizer = optim.Adam(model.parameters(),lr = LEARNINGRATE) #optim.SGD()\n",
        "\n",
        "# maybe only train last part\n",
        "# turn grad of pre layers off\n",
        "\n",
        "#for name, param in model.named_parameters():\n",
        "#    print(name, param.requires_grad)\n",
        "\n",
        "print(\"--------------------------------------------------------------------\\n\")\n",
        "\n",
        "###############################################################################\n",
        "# directory for output files for model version / loading model\n",
        "###############################################################################\n",
        "\n",
        "foldername = \"FCN_v\" + VERSION + \"/\"\n",
        "FOLDERPATH = os.path.join(ROOTPATH, foldername)\n",
        "\n",
        "###############################################################################\n",
        "# save parameters of model\n",
        "###############################################################################\n",
        "\n",
        "if MODE == \"train\":\n",
        "  if not os.path.exists(FOLDERPATH):\n",
        "    os.mkdir(FOLDERPATH)\n",
        "\n",
        "    parameters = {\"Modelversion\" : VERSION,\n",
        "                  \"Batchsize\" : BATCHSIZE,\n",
        "                  \"Learningrate\" : LEARNINGRATE,\n",
        "                  \"Number Epochs\" : NUMBEREPOCHS,\n",
        "                  \"Image resize\" : RESIZE,\n",
        "                  \"untouched pretrained weights\" : PRETRAINED,\n",
        "                  \"Smaller VGG\" : SMALLVGG,\n",
        "                  \"Optimizer\" : str(Optimizer),\n",
        "                  \"Model architectur\" : str(model)}\n",
        "\n",
        "    with open(FOLDERPATH + \"training_parameters.json\", 'w') as file:\n",
        "      json.dump(parameters, file)\n",
        "\n",
        "    print(\"File with trainingparameters of model saved in {}.\".format(FOLDERPATH))\n",
        "    print(\"\\n------------------------------------------------------------------\\n\")\n",
        "\n",
        "  else:\n",
        "    test = 1\n",
        "    #sys.exit(\"Folder for model allready exists.\")\n",
        "\n",
        "###############################################################################\n",
        "# reload model for evaluation\n",
        "###############################################################################\n",
        "\n",
        "if MODE == \"evaluate\":\n",
        "\n",
        "  if not os.path.exists(os.path.join(FOLDERPATH + \"training_parameters.json\")):\n",
        "    sys.exit(\"File with parameters doesnt exists\")\n",
        "\n",
        "  with open(FOLDERPATH + \"training_parameters.json\", newline='') as file:\n",
        "    parameters = json.load(file)\n",
        "\n",
        "  VERSION = parameters[\"Modelversion\"]\n",
        "  BATCHSIZE = parameters[\"Batchsize\"]\n",
        "  LEARNINGRATE = parameters[\"Learningrate\"]\n",
        "  NUMBEREPOCHS = parameters[\"Number Epochs\"]\n",
        "  RESIZE = parameters[\"Image resize\"]\n",
        "  PRETRAINED = parameters[\"untouched pretrained weights\"]\n",
        "  SMALLVGG = parameters[\"Smaller VGG\"]\n",
        "\n",
        "  print(\"Loaded model version {} for evaluation\".format(VERSION))\n",
        "  print(\"\\n------------------------------------------------------------------\\n\")\n",
        "\n",
        "###############################################################################\n",
        "# load dataset for training\n",
        "###############################################################################\n",
        "\n",
        "# open training data, has 3680 samples\n",
        "# transform images (input images and lapels / mregion maps)to same sizes\n",
        "pets_train = OxfordIIITPet(root=ROOTPATH, split=\"trainval\",\n",
        "                           transform =Resize(RESIZE),\n",
        "                           target_transform = Resize(RESIZE),\n",
        "                           target_types=\"segmentation\", download=False)\n",
        "\n",
        "# open test data, has 3669 samples\n",
        "# transform images (input images and lapels / mregion maps)to same sizes\n",
        "pets_test = OxfordIIITPet(root=ROOTPATH, split=\"test\",\n",
        "                          transform = Resize(RESIZE),\n",
        "                          target_transform = Resize(RESIZE),\n",
        "                          target_types=\"segmentation\", download=False)\n",
        "\n",
        "# use smaller dataset for faster runntime during debugging\n",
        "if SMALLDATASET:\n",
        "    print(\"Use reduced size of dataset for faster runtime. ONLY FOR DEBUGGING!\\n\")\n",
        "    pets_train = smallerDataset(pets_train, smaller_train_dataset_size)\n",
        "    pets_test = smallerDataset(pets_test, smaller_test_dataset_size)\n",
        "\n",
        "# load data for training, use custom collate function\n",
        "# to handle non-tensor format of original dataset\n",
        "train_dataload = DataLoader(pets_train, batch_size=BATCHSIZE,\n",
        "                            shuffle=True,\n",
        "                            collate_fn= lambda b, params=RESIZE: customCollate(b, params))\n",
        "\n",
        "# load data for testing, use custom collate function\n",
        "# to handle non-tensor format of original dataset\n",
        "test_dataload = DataLoader(pets_test, batch_size=BATCHSIZE,\n",
        "                           shuffle=True,\n",
        "                           collate_fn= lambda b, params=RESIZE: customCollate(b, params))\n",
        "\n",
        "print(\"Dataset loaded.\")\n",
        "print(\"\\n------------------------------------------------------------------\\n\")\n",
        "\n",
        "###############################################################################\n",
        "# training and testing\n",
        "###############################################################################\n",
        "\n",
        "if MODE == \"train\":\n",
        "  print(\"Starting training.\")\n",
        "\n",
        "  if PRETRAINED:\n",
        "    print(\"Dont train pretrained weights of the VGG16 features.\")\n",
        "    for param in model.features.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  training_loss, test_loss = trainModel(model, lossFunction, Optimizer,\n",
        "                                        train_dataload, test_dataload,\n",
        "                                        NUMBEREPOCHS, FOLDERPATH)\n",
        "\n",
        "  #plotLosses(training_loss, test_loss, FOLDERPATH)\n",
        "\n",
        "\n",
        "  print(\"Finished training.\")\n",
        "  print(\"\\n------------------------------------------------------------------\\n\")\n",
        "\n",
        "###############################################################################\n",
        "# only evaluation\n",
        "###############################################################################\n",
        "\n",
        "if MODE == \"evaluate\":\n",
        "  print(\"Starting evaluation.\")\n",
        "\n",
        "\n",
        "  print(\"Finished evaluation.\")\n",
        "  print(\"\\n------------------------------------------------------------------\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open(name_model + \"loss_batches.csv\", 'w') as file:\n",
        "  file.write(\"batch nr.; loss \\n\")\n",
        "\n",
        "with open(name_model + \"loss_epochs.csv\", 'w') as file:\n",
        "  file.write(\"epoch nt.; loss \\n\")\n",
        "\n",
        "for epoch in range(number_epochs):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  data_size = len(pets_train)\n",
        "\n",
        "  running_loss = 0\n",
        "  batch_number = 0 #is equal to batch_size (just for debugging here)\n",
        "\n",
        "  for i, dataset in enumerate(train_dataload):\n",
        "\n",
        "    # unpack images and labels of batch\n",
        "    images , labels, _ = dataset\n",
        "\n",
        "    #print(\"Size of labels (targets):\")\n",
        "    #print(labels.shape) #(2, imagesize) (N,H,W)\n",
        "\n",
        "    # reset optimizer gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(images)\n",
        "\n",
        "    #print(\"Size of outputs (after model):\")\n",
        "    #print(outputs.shape) #(2, 2, imagesize) (N,C,H,W)\n",
        "\n",
        "    # compute loss\n",
        "    loss = loss_function(outputs, labels)\n",
        "\n",
        "    # backward pass and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    batch_number += 1\n",
        "\n",
        "    # report of batch at the moment\n",
        "    #print(\"Batch number {} / {} in Epoch {}\".format(i+1,int(data_size/batch_size), epoch+1))\n",
        "    #print(\"Loss for this batch: {}\".format(loss))\n",
        "\n",
        "    # write loss for batch in file\n",
        "    with open(name_model + \"loss_batches.csv\", 'a') as file:\n",
        "      file.write(\"{};\\t{}\\n\".format(i+1, loss))\n",
        "\n",
        "    # Print epoch statistics\n",
        "    epoch_loss = running_loss / batch_number\n",
        "    print(\"Epoch [{}/{}], Loss: {}\".format(epoch+1,number_epochs,epoch_loss))\n",
        "    print(\"{} updates in this epoch.\".format(batch_number))\n",
        "\n",
        "\n",
        "\n",
        "    # write loss for epoch in file\n",
        "    with open(name_model + \"loss_epochs.csv\", 'a') as file:\n",
        "      file.write(\"{};\\t{}\\n\".format(epoch, epoch_loss))\n",
        "\n",
        "torch.save(model.state_dict(), name_model + \"trained\" )\n",
        "print(\"Training finished, model saved.\")\n",
        "\n",
        "# show output after training\n",
        "show_output(images[0], outputs[0])\n",
        "\n",
        "\n",
        "print(\"\\n------------------------------------------------------------------\\n\")\n",
        "\n",
        "# test model\n",
        "\n",
        "batch_number = 0\n",
        "running_loss = 0\n",
        "for i, dataset in enumerate(test_dataload):\n",
        "\n",
        "        # unpack images and labels of batch\n",
        "        images , labels, labels_orig = dataset\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        output = model(images)\n",
        "\n",
        "\n",
        "\n",
        "        # compute loss\n",
        "        loss = loss_function(output, labels)\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        batch_number += 1\n",
        "\n",
        "\n",
        "\n",
        "        # report of batch at the moment\n",
        "        #print(\"Batch number {} / {} in Epoch {}\".format(i+1,int(data_size/batch_size), epoch+1))\n",
        "        #print(\"Loss for this batch: {}\".format(loss))\n",
        "\n",
        "        # write loss for batch in file\n",
        "        with open(name_model + \"_loss_test.csv\", 'a') as file:\n",
        "            file.write(\"{};\\t{}\\n\".format(i+1, loss))\n",
        "\n",
        "test_loss = running_loss / batch_number\n",
        "print(\"Testing, Loss: {}\".format(test_loss))\n",
        "print(\"Testing with {} batches\".format(batch_number))\n",
        "\n",
        "# show output after testing\n",
        "show_output(images[0], output[0])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qi1vPJ0eu_iz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "outputId": "567c2989-7ade-443d-b7c0-67acd5180beb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------\n",
            "\n",
            "Use reduced size of dataset for faster runtime. ONLY FOR DEBUGGING!\n",
            "\n",
            "Dataset loaded.\n",
            "\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Starting training.\n",
            "Dont train pretrained weights of the VGG16 features.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [1/10]\n",
            "5 updates in this epoch.\n",
            "Trainingloss: 0.5211837470531464\n",
            "Testingloss: 2.6446775794029236\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-04f7725dde20>\u001b[0m in \u001b[0;36m<cell line: 185>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m   training_loss, test_loss = trainModel(model, lossFunction, Optimizer, \n\u001b[0m\u001b[1;32m    194\u001b[0m                                         \u001b[0mtrain_dataload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                                         NUMBEREPOCHS, FOLDERPATH)\n",
            "\u001b[0;32m<ipython-input-14-0cb8d18f7d98>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(model, lossFunction, Optimizer, train_dataload, test_dataload, NUMBEREPOCHS, FOLDERPATH)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m# test in each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# print epoch statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-0cb8d18f7d98>\u001b[0m in \u001b[0;36mtestModel\u001b[0;34m(model, lossFunction, test_dataload)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-6840504cee5f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m#print(\"Output after classifier\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}