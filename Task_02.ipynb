{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flosch9/deep_learning_home_exam/blob/main/Task_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load modules"
      ],
      "metadata": {
        "id": "Nt3-MycpxKDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj16FXLexE_h",
        "outputId": "c80f4176-507a-4ee4-bb79-22951faac8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting utils\n",
            "  Downloading utils-1.0.2.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: utils\n",
            "  Building wheel for utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13906 sha256=976e92dcc0aec7e191dfd177648dcecea7997a32a00983bdec6fb102c562b17c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/39/f5/9d0ca31dba85773ececf0a7f5469f18810e1c8a8ed9da28ca7\n",
            "Successfully built utils\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "4-PLNuxH1zdm",
        "outputId": "4bf0655f-48dd-421a-e323-949aaf408ee3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-8b78ec40b86f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define and load model (model.py)\n",
        "\n",
        "```\n",
        "# Als Code formatiert\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dfS5ObhvvHNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import utils\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "\n",
        "\n",
        "class FCN32(nn.Module):\n",
        "    def __init__(self, output_size = (128,128), num_classes = 2, small_vgg = False):\n",
        "        super(FCN32, self).__init__()\n",
        "\n",
        "        # first part is regualr vgg16 (without batch normalization)?\n",
        "        if small_vgg:\n",
        "          self.features = vgg16(weights = VGG16_Weights.IMAGENET1K_V1).features[0:28]\n",
        "        else:\n",
        "          self.features = vgg16(weights = VGG16_Weights.IMAGENET1K_V1).features\n",
        "\n",
        "\n",
        "        # only choose some parts of vgg16? [0:28]\n",
        "        # set ceil mode to true\n",
        "        #self.features[6].ceil_mode = True\n",
        "        #self.features[13].ceil_mode = True\n",
        "        #self.features[23].ceil_mode = True\n",
        "        #self.features[33].ceil_mode = True\n",
        "        #self.features[43].ceil_mode = True\n",
        "\n",
        "        # classifier is now replaced with another cnn (instead of a fc)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Conv2d(512, 4024, kernel_size=(3,3), stride=(1,1), padding=(1,1)), # 512 output from last cnn/maxpool layer #maybe only 1000 channels\n",
        "            # use filter size 1024 or 4096\n",
        "            nn.ReLU(True),\n",
        "            #with Relu? with Batchnorm? with maxpool?\n",
        "            # 7x7 filter\n",
        "            nn.Conv2d(4024, num_classes, kernel_size=1, stride=(1,1), padding=(1,1))\n",
        "            #nn.ReLU(True)\n",
        "\n",
        "            #nn.Softmax()\n",
        "            #softmax produces niceer output in the end\n",
        "\n",
        "            # makes difference in the output, and in the loss which (none) activation is used\n",
        "        )\n",
        "        self.upsample = nn.Sequential(\n",
        "            # what is with upsampling meant? this (just resizing) or the deconvolution before upsample and transposeconv2d the same???\n",
        "            # this one is not trainable but easier\n",
        "            nn.UpsamplingBilinear2d(size=(output_size)),\n",
        "            nn.Softmax()\n",
        "\n",
        "            #nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2, padding=0)#, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)\n",
        "            # then output needs to be adjusted and classes in one channel\n",
        "            # try to set ceiling of maxpool to true\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        #print(\"Output after classifier\")\n",
        "        #print(x.shape)\n",
        "        x = self.upsample(x)\n",
        "        #print(\"Output after upsampling\")\n",
        "        #print(x.shape)\n",
        "        return x\n",
        "\n",
        "#model = FCN32(output_size=(128,128))\n",
        "\n",
        "# print outputs of a model\n",
        "#print(vgg16_bn().features)\n",
        "#print(vgg16_bn().classifier)\n",
        "\n",
        "#print(vgg16_bn())\n",
        "#model = FCN32()\n",
        "\n",
        "# print(FCN32().features)\n",
        "# set ceil_modes to true\n",
        "#print(model.features[6].ceil_mode)\n",
        "\n"
      ],
      "metadata": {
        "id": "r-J0ghhDvoCf"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount drive to load data from drive"
      ],
      "metadata": {
        "id": "Lya780NE5QvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fw7o-Z81KfC",
        "outputId": "440a6999-e0c0-471b-fe7f-189e06d2cac5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/drive/MyDrive/Deep_learning_home_exam\""
      ],
      "metadata": {
        "id": "edPie4At5WhN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eXqMHU6TvE_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define train and test functions (traintestfuncs.py)"
      ],
      "metadata": {
        "id": "bp7kvPYnv3Tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import PILToTensor, ToTensor, ToPILImage, Resize\n",
        "\n",
        "# not needed in notebook\n",
        "#from model import FCN32\n",
        "\n",
        "\n",
        "def smallerDataset(dataset, size):\n",
        "\n",
        "    smaller_dataset = []\n",
        "\n",
        "    for i in range(size):\n",
        "        smaller_dataset.append(dataset[i])\n",
        "\n",
        "    return(smaller_dataset)\n",
        "\n",
        "\n",
        "# since the dataloader can t handle the PIL Image class of the original dataset\n",
        "# for each batch the lables and images have to be stacked to a tensor manually\n",
        "# in this step also the PIL Images are transformed to a tensor\n",
        "# do not use ToTensor for target image since it destroys the class\n",
        "def customCollate(batch, resize):\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    for dataset in batch:\n",
        "\n",
        "        image = ToTensor()(dataset[0])\n",
        "        label = PILToTensor()(dataset[1]) # important else target fckd up with classes\n",
        "        label = label.view(resize) #to get rid of the (implizit) given channel\n",
        "\n",
        "        label = label.long() # also importantz for CE-Loss, excpects long\n",
        "        label = torch.sub(label, 1) # also important since 3 classes -> [0,3), but original it was [1,3]\n",
        "\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "    return(torch.stack(images), torch.stack(labels))\n",
        "\n",
        "\n",
        "def showLosses(training_loss, test_loss, path_to_save):\n",
        "  return()\n",
        "\n",
        "\n",
        "def trainModel(model, name_model, number_epochs,\n",
        "               train_dataload, test_dataload,):\n",
        "    with open(name_model + \"loss_batches.csv\", 'w') as file:\n",
        "            file.write(\"batch nr.; loss \\n\")\n",
        "\n",
        "    with open(name_model + \"loss_epochs.csv\", 'w') as file:\n",
        "            file.write(\"epoch nt.; loss \\n\")\n",
        "\n",
        "    for epoch in range(number_epochs):\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        data_size = len(pets_train)\n",
        "\n",
        "        running_loss = 0\n",
        "        batch_number = 0 #is equal to batch_size (just for debugging here)\n",
        "\n",
        "    for i, dataset in enumerate(train_dataload):\n",
        "\n",
        "        # unpack images and labels of batch\n",
        "        images , labels, _ = dataset\n",
        "\n",
        "        #print(\"Size of labels (targets):\")\n",
        "        #print(labels.shape) #(2, imagesize) (N,H,W)\n",
        "\n",
        "        # reset optimizer gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        #print(\"Size of outputs (after model):\")\n",
        "        #print(outputs.shape) #(2, 2, imagesize) (N,C,H,W)\n",
        "\n",
        "        # compute loss\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        batch_number += 1\n",
        "\n",
        "        # report of batch at the moment\n",
        "        #print(\"Batch number {} / {} in Epoch {}\".format(i+1,int(data_size/batch_size), epoch+1))\n",
        "        #print(\"Loss for this batch: {}\".format(loss))\n",
        "\n",
        "        # write loss for batch in file\n",
        "        with open(name_model + \"loss_batches.csv\", 'a') as file:\n",
        "            file.write(\"{};\\t{}\\n\".format(i+1, loss))\n",
        "\n",
        "    # Print epoch statistics\n",
        "    epoch_loss = running_loss / batch_number\n",
        "    print(\"Epoch [{}/{}], Loss: {}\".format(epoch+1,number_epochs,epoch_loss))\n",
        "    print(\"{} updates in this epoch.\".format(batch_number))\n",
        "\n",
        "\n",
        "\n",
        "    # write loss for epoch in file\n",
        "    with open(name_model + \"loss_epochs.csv\", 'a') as file:\n",
        "            file.write(\"{};\\t{}\\n\".format(epoch, epoch_loss))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def testModel(model, test_images, test_labels_merched, original_labels):\n",
        "  print(\"Testing Model:\\n\")\n",
        "  model.eval()\n",
        "\n",
        "  output = model(test_images)\n",
        "\n",
        "  return()\n",
        "\n",
        "\n",
        "\n",
        "def evaluateFCN():\n",
        "  return()\n",
        "\n",
        "\n",
        "def test_model(model, test_images, test_labels_merched, original_labels):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    output = model(test_images)\n",
        "\n",
        "    show_output(test_images[0], output[0])\n",
        "\n",
        "    return()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# short function for displaying initial image next to segmentation\n",
        "def display_data(data_point):\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize =(10,6))\n",
        "    ax[0].imshow(ToPILImage()(data_point[0][0]))\n",
        "    ax[1].imshow(ToPILImage()(data_point[1][0]))\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return()\n",
        "\n",
        "###############################################################################\n",
        "# testing model and displaying outputs\n",
        "###############################################################################\n",
        "\n",
        "def show_output(initial_image, model_output):\n",
        "\n",
        "    #print(\"Shape initial: {}\".format(initial_image.shape)) #(3, H,W)\n",
        "    #print(\"Shape segmentation: {}\".format(model_output.shape)) #(2,H,W)\n",
        "    #print(\"Unique values segmentation: {}\".format(torch.unique(model_output)))\n",
        "    #print(\"Output segmentation:\")\n",
        "    #print(model_output)\n",
        "\n",
        "    model_output = model_output[1,:,:]\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize =(10,6))\n",
        "    ax[0].imshow(ToPILImage()(initial_image))\n",
        "    ax[1].imshow(ToPILImage()(model_output), cmap = \"gray\")\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    return()\n",
        "\n",
        "\n",
        "def show_uncertainity_map():\n",
        "    return()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1ij5b-Qhv7P2"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and evaluate model (main.py)"
      ],
      "metadata": {
        "id": "czdp_KzuvtfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import utils\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import PILToTensor, ToTensor, ToPILImage, Resize\n",
        "\n",
        "#from model import FCN32\n",
        "#import traintestfuncs\n",
        "\n",
        "#from test import show_output, test_model, show_uncertainity_map\n",
        "\n",
        "###############################################################################\n",
        "# general Parameters for training (make adjustments here)\n",
        "###############################################################################\n",
        "# Path for notebook\n",
        "ROOTPATH = \"/content/drive/MyDrive/Deep_learning_home_exam/data/problem2/\"\n",
        "\n",
        "# Path for local\n",
        "#ROOTPATH = \"home_exam\\data\\problem2\\\\\"\n",
        "\n",
        "# for saving model with trained parameters\n",
        "VERSION = \"02\"\n",
        "\n",
        "MODE = \"train\" # \"train\" or \"evaluate\"\n",
        "\n",
        "# parameters for training\n",
        "NUMBEREPOCHS = 10\n",
        "BATCHSIZE = 32\n",
        "LEARNINGRATE = 0.001\n",
        "\n",
        "# resize dataset to see faster runtrough\n",
        "SMALLDATASET = True\n",
        "smaller_train_dataset_size = 10\n",
        "smaller_test_dataset_size = 10\n",
        "\n",
        "\n",
        "# resizing images of dataset so that they all have the same size\n",
        "# (which they originaly dont have)\n",
        "RESIZE =(512,512)\n",
        "# 56 too small\n",
        "#  128 #TODO\n",
        "# 256 ok -> version 01\n",
        "# resize to smaller images (not really good)\n",
        "\n",
        "# bigger image better, together with drop of last two maxpool layers\n",
        "\n",
        "# resize to smaller image maybe\n",
        "# use kernelsize 7x7 in last step of convolution output\n",
        "# google collab train on\n",
        "\n",
        "PRETRAINED = True\n",
        "SMALLVGG = False\n",
        "\n",
        "model = FCN32(output_size=RESIZE, num_classes=2, small_vgg = SMALLVGG)\n",
        "\n",
        "lossFunction = nn.CrossEntropyLoss() #nn.MSELoss()\n",
        "\n",
        "Optimizer = optim.Adam(model.parameters(),lr = LEARNINGRATE) #optim.SGD()\n",
        "\n",
        "# maybe only train last part\n",
        "# turn grad of pre layers off\n",
        "\n",
        "#for name, param in model.named_parameters():\n",
        "#    print(name, param.requires_grad)\n",
        "\n",
        "print(\"--------------------------------------------------------------------\\n\")\n",
        "\n",
        "###############################################################################\n",
        "# directory for output files for model version / loading model\n",
        "###############################################################################\n",
        "\n",
        "foldername = \"FCN_v\" + VERSION + \"/\"\n",
        "FOLDERPATH = os.path.join(ROOTPATH, foldername)\n",
        "\n",
        "###############################################################################\n",
        "# save parameters of model\n",
        "###############################################################################\n",
        "\n",
        "if MODE == \"train\":\n",
        "  if not os.path.exists(FOLDERPATH):\n",
        "    os.mkdir(FOLDERPATH)\n",
        "\n",
        "    with open(FOLDERPATH + \"training_paramters.txt\", 'w') as file:\n",
        "      file.write(\"Modelversion; \\t\" + str(VERSION) + '\\n')\n",
        "      file.write(\"Batchsize; \\t\" + str(BATCHSIZE) + '\\n')\n",
        "      file.write(\"Learning rate; \\t\" + str(LEARNINGRATE) + '\\n')\n",
        "      file.write(\"Number Epochs; \\t\" + str(NUMBEREPOCHS)+ '\\n')\n",
        "      file.write(\"Image resize; \\t(\" + str(RESIZE) + ')\\n')\n",
        "      file.write(\"untouched pretrained weights; \\t\" + str(PRETRAINED) + '\\n')\n",
        "      file.write(\"Smaller Vgg; \\t\" + str(SMALLVGG) + '\\n')\n",
        "      file.write(\"Optimizer; \\t\" + str(Optimizer) + '\\n')\n",
        "      file.write(\"Model architecture; \\t\" + str(model) + '\\n')\n",
        "\n",
        "    print(\"File with trainingparameters of model saved in {}.\".format(FOLDERPATH))\n",
        "    print(\"\\n------------------------------------------------------------------\\n\")\n",
        "\n",
        "  else:\n",
        "    sys.exit(\"Folder for model allready exists.\")\n",
        "\n",
        "###############################################################################\n",
        "# reload model for evaluation\n",
        "###############################################################################\n",
        "\n",
        "if MODE == \"evaluate\":\n",
        "\n",
        "  print(\"Loaded model version {} for evaluation\".format(VERSION))\n",
        "  print(\"\\n------------------------------------------------------------------\\n\")\n",
        "\n",
        "###############################################################################\n",
        "# load dataset for training\n",
        "###############################################################################\n",
        "\n",
        "# open training data, has 3680 samples\n",
        "# transform images (input images and lapels / mregion maps)to same sizes\n",
        "pets_train = OxfordIIITPet(root=ROOTPATH, split=\"trainval\",\n",
        "                           transform =Resize(RESIZE),\n",
        "                           target_transform = Resize(RESIZE),\n",
        "                           target_types=\"segmentation\", download=False)\n",
        "\n",
        "# open test data, has 3669 samples\n",
        "# transform images (input images and lapels / mregion maps)to same sizes\n",
        "pets_test = OxfordIIITPet(root=ROOTPATH, split=\"test\",\n",
        "                          transform = Resize(RESIZE),\n",
        "                          target_transform = Resize(RESIZE),\n",
        "                          target_types=\"segmentation\", download=False)\n",
        "\n",
        "# use smaller dataset for faster runntime during debugging\n",
        "if SMALLDATASET:\n",
        "    print(\"Use reduced size of dataset for faster runtime. ONLY FOR DEBUGGING!\")\n",
        "    pets_train = smallerDataset(pets_train, smaller_train_dataset_size)\n",
        "    pets_test = smallerDataset(pets_test, smaller_test_dataset_size)\n",
        "\n",
        "# load data for training, use custom collate function\n",
        "# to handle non-tensor format of original dataset\n",
        "train_dataload = DataLoader(pets_train, batch_size=BATCHSIZE,\n",
        "                            shuffle=True, collate_fn= customCollate)\n",
        "\n",
        "# load data for testing, use custom collate function\n",
        "# to handle non-tensor format of original dataset\n",
        "test_dataload = DataLoader(pets_test, batch_size=BATCHSIZE,\n",
        "                           shuffle=True, collate_fn= customCollate)\n",
        "\n",
        "print(\"Dataset loaded.\")\n",
        "print(\"\\n------------------------------------------------------------------\\n\")\n",
        "\n",
        "###############################################################################\n",
        "# training and testing\n",
        "###############################################################################\n",
        "\n",
        "if MODE == \"train\":\n",
        "  print(\"Starting training.\")\n",
        "\n",
        "  if PRETRAINED:\n",
        "    print(\"Dont train pretrained weights of the VGG16 features.\")\n",
        "    for param in model.features.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  training_loss, test_loss = trainModel()\n",
        "\n",
        "  showLosses(training_loss, test_loss, FOLDERPATH)\n",
        "\n",
        "\n",
        "  print(\"Finished training.\")\n",
        "  print(\"\\n------------------------------------------------------------------\\n\")\n",
        "\n",
        "###############################################################################\n",
        "# only evaluation\n",
        "###############################################################################\n",
        "\n",
        "if MODE == \"evaluate\":\n",
        "  print(\"Starting evaluation.\")\n",
        "\n",
        "\n",
        "  print(\"Finished evaluation.\")\n",
        "  print(\"\\n------------------------------------------------------------------\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open(name_model + \"loss_batches.csv\", 'w') as file:\n",
        "  file.write(\"batch nr.; loss \\n\")\n",
        "\n",
        "with open(name_model + \"loss_epochs.csv\", 'w') as file:\n",
        "  file.write(\"epoch nt.; loss \\n\")\n",
        "\n",
        "for epoch in range(number_epochs):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  data_size = len(pets_train)\n",
        "\n",
        "  running_loss = 0\n",
        "  batch_number = 0 #is equal to batch_size (just for debugging here)\n",
        "\n",
        "  for i, dataset in enumerate(train_dataload):\n",
        "\n",
        "    # unpack images and labels of batch\n",
        "    images , labels, _ = dataset\n",
        "\n",
        "    #print(\"Size of labels (targets):\")\n",
        "    #print(labels.shape) #(2, imagesize) (N,H,W)\n",
        "\n",
        "    # reset optimizer gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(images)\n",
        "\n",
        "    #print(\"Size of outputs (after model):\")\n",
        "    #print(outputs.shape) #(2, 2, imagesize) (N,C,H,W)\n",
        "\n",
        "    # compute loss\n",
        "    loss = loss_function(outputs, labels)\n",
        "\n",
        "    # backward pass and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    batch_number += 1\n",
        "\n",
        "    # report of batch at the moment\n",
        "    #print(\"Batch number {} / {} in Epoch {}\".format(i+1,int(data_size/batch_size), epoch+1))\n",
        "    #print(\"Loss for this batch: {}\".format(loss))\n",
        "\n",
        "    # write loss for batch in file\n",
        "    with open(name_model + \"loss_batches.csv\", 'a') as file:\n",
        "      file.write(\"{};\\t{}\\n\".format(i+1, loss))\n",
        "\n",
        "    # Print epoch statistics\n",
        "    epoch_loss = running_loss / batch_number\n",
        "    print(\"Epoch [{}/{}], Loss: {}\".format(epoch+1,number_epochs,epoch_loss))\n",
        "    print(\"{} updates in this epoch.\".format(batch_number))\n",
        "\n",
        "\n",
        "\n",
        "    # write loss for epoch in file\n",
        "    with open(name_model + \"loss_epochs.csv\", 'a') as file:\n",
        "      file.write(\"{};\\t{}\\n\".format(epoch, epoch_loss))\n",
        "\n",
        "torch.save(model.state_dict(), name_model + \"trained\" )\n",
        "print(\"Training finished, model saved.\")\n",
        "\n",
        "# show output after training\n",
        "show_output(images[0], outputs[0])\n",
        "\n",
        "\n",
        "print(\"\\n------------------------------------------------------------------\\n\")\n",
        "\n",
        "# test model\n",
        "\n",
        "batch_number = 0\n",
        "running_loss = 0\n",
        "for i, dataset in enumerate(test_dataload):\n",
        "\n",
        "        # unpack images and labels of batch\n",
        "        images , labels, labels_orig = dataset\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        output = model(images)\n",
        "\n",
        "\n",
        "\n",
        "        # compute loss\n",
        "        loss = loss_function(output, labels)\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        batch_number += 1\n",
        "\n",
        "\n",
        "\n",
        "        # report of batch at the moment\n",
        "        #print(\"Batch number {} / {} in Epoch {}\".format(i+1,int(data_size/batch_size), epoch+1))\n",
        "        #print(\"Loss for this batch: {}\".format(loss))\n",
        "\n",
        "        # write loss for batch in file\n",
        "        with open(name_model + \"_loss_test.csv\", 'a') as file:\n",
        "            file.write(\"{};\\t{}\\n\".format(i+1, loss))\n",
        "\n",
        "test_loss = running_loss / batch_number\n",
        "print(\"Testing, Loss: {}\".format(test_loss))\n",
        "print(\"Testing with {} batches\".format(batch_number))\n",
        "\n",
        "# show output after testing\n",
        "show_output(images[0], output[0])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qi1vPJ0eu_iz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "038dc0e8-2dbc-4530-d6a4-e68f5bc005a2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "Folder for model allready exists.",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Folder for model allready exists.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}